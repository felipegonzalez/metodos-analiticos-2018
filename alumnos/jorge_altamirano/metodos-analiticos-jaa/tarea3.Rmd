---
title: 'Tarea 3 - LSH: Entity matching'
output:
  html_document:
    df_print: paged
---

_175904 - Jorge III Altamirano Astorga_


En este ejemplo veremos como usar LSH de una manera simple para encontrar registros que se refieren al mismo elemento, pero pueden diferir en cómo están registrados (entity matching).

## Datos

Los [datos](https://dbs.uni-leipzig.de/de/research/projects/object_matching/fever/benchmark_datasets_for_entity_resolution) para este ejempo particular trata con dos fuentes bibliográficas (DBLP, ACM)
de artículos y conferencias de cómputo. 


```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(textreuse)
acm <- read_csv('../../../datos/similitud/entity_matching/ACM.csv')
dbl <- read_csv('../../../datos/similitud/entity_matching/DBLP2.csv')
```

```{r}
head(acm)
head(dbl)
nrow(acm)
nrow(dbl)
```

**Pregunta**: ¿si intentas una aproximación por fuerza bruta, cuántas comparaciones
tendrías que hacer?

```{r}
norma <- function(x){
  sqrt(sum(x ^ 2))
}
dist_coseno <- function(x, y){
  1 - sum(x*y) / (norma(x) * norma(y))
}
df1 <- rbind(acm[,-1], dbl[,-1]) %>% data.frame %>%
           add_column(id_1 = 1:(nrow(acm)+nrow(dbl)), .before = 1)
df_agrup1 <- df1 %>% gather('variable', 'valor', -id_1) %>%
                   group_by(id_1) %>%
                   arrange(variable) %>%
                   summarise(vec_1 = list(valor))
df_pares1 <- df_agrup1 %>% 
            crossing(df_agrup1 %>% 
                       rename(id_2 = id_1, vec_2 = vec_1)) %>%
            filter(id_1 < id_2) #%>%
options("mc.cores" = 3L)
# df_pares1 <- df_pares1 %>% mutate(dist = map2_dbl(vec_1, vec_2, dist_coseno))
df_pares1
```

### choice

_Dependerá si queremos combinar por separado o unidas._


```{r}
#Para acm.csv
choose(nrow(acm),2)

#Para dbl.csv
choose(nrow(dbl),2)

#Combinación
choose(nrow(acm) + nrow(dbl),2)
```


## Shingling y hashing

Vamos a poner todos los documentos en una sola lista. Aunque al final
encontremos elementos de la misma fuente en la misma cubeta, podemos
filtrar estos. En este caso escogemos 20 hashes agrupados en 5 bandas, y 
shingles de tamaño 4, y usamos sólo título y autor.

```{r}
acm_1 <- acm %>% select(title, authors) %>% 
        mutate(texto = paste(title, authors, sep = "    "))
dbl_1 <- dbl %>% select(title, authors) %>% 
         mutate(texto = paste(title, authors, sep = "    "))
acm_1
dbl_1
```

**Pregunta**: ¿por qué incluimos algún espacio en blanco entre título y autor?

Estamos usando tejas, como los titulos y nombres de autores llevan espacios, queremos aceptar estos espacios tambien en los inicios y finales de tejas.


```{r}
shingle_chars <- function(string, lowercase = FALSE, k = 4){
  # produce shingles (con repeticiones)
  if(lowercase) {
    string <- str_to_lower(string)
  }
  shingles <- seq(1, nchar(string) - k + 1) %>%
    map_chr(function(x) substr(string, x, x + k - 1))
  shingles
}

minhasher <- minhash_generator(20)
options("mc.cores" = 14L)
nombres_acm <- paste0("acm-doc-", 1:length(acm_l$texto))
nombres_dbl <- paste0("dbl-doc-", 1:length(dbl_l$texto))
nombres <- c(nombres_acm, nombres_dbl)
texto <- c(acm$texto, dbl$texto)
names(texto) <- nombres
corpus <- TextReuseCorpus(text = texto,
                          minhash_func = minhasher,
                          tokenizer = shingle_chars, k = 4,
                          progress = FALSE, skip_short = FALSE)

lsh_conf <- lsh(corpus, bands = 5) 
```


**Pregunta**: Haz una gráfica mostrando qué porcentaje de cada nivel
de similitud tiene probabilidad de ser capturado para este problema.
Explica en qué casos esto sería razonable, y si consideras apropiado
cambia este número.

_Con 20 bandas y 5 hashes ($ k=20, b=5 $). Por lo tanto,_
$$
k=br \rightarrow r =  \frac{k}{b} = \frac {20}{5} = 4 = r
$$

_Que tendrá una similitud similar a 0.7_

```{r}
graficar_curvas <- function(df_br, colour = TRUE){
  r <- df_br$r
  b <- df_br$b
  datos_graf <- data_frame(s = seq(0, 1, 0.01))
  curvas_similitud <- data_frame(b = b, r =r) %>%
                    group_by(r, b) %>%
                    mutate(datos = map2(r, b, function(r, b){
                      datos_graf %>% 
                      mutate(prob = 1 - (1 - s ^ r) ^b)
                    })) %>%
                    unnest
  graf_salida <- ggplot(curvas_similitud, 
                        aes(x = s, y = prob, 
                            colour = as.factor(interaction(b,r)))) +
                 geom_line(size=1.1) + 
                 labs(x = 'similitud', y= 'probablidad de ser candidato',
                      colour = 'b.r') 
  if(colour){
    graf_salida + scale_colour_manual(values=cb_palette)
  }
                 
  graf_salida
}
graficar_curvas(data_frame(b = 222, r = 4)) + 
                 geom_vline(xintercept = 0.7)
```


## Evaluación de candidatos

```{r}
options("mc.cores" = 14L)
corpus <- TextReuseCorpus(text = texto,
                          minhash_func = minhasher,
                          tokenizer = shingle_chars, k = 4,
                          progress = FALSE, skip_short = FALSE)
lsh_conf <- lsh(corpus, bands = 20)
candidatos <- lsh_candidates(lsh_conf)
candidatos <- lsh_compare(candidatos, corpus, jaccard_similarity)
candidatos <- candidatos %>% arrange(desc(score))
candidatos
```

Podemos ver el contenido de un texto de esta manera:

```{r}
corpus[["acm-doc-1012"]]$content
```


**Pregunta**: ¿Cuántas comparaciones tuviste qué hacer (cálculos de similitud)?

**Pregunta**:  Filtra esta tabla para que
solo contenga pares que vienen de diferentes tablas (acm y dbl).
Considera ahora los elementos con siimilitud uno. ¿Se refieren al
mismo artículo en las dos fuentes? 

**Pregunta**: Ahora considera los elementos 
con similitud más baja que capturaste. Examina varios casos y concluye
si hay pares que no se refieren al mismo artículo, y por qué.

```{r}
#aquí pon código.
```

**Pregunta**: propón un punto de corte para la tabla de arriba, según tus
observaciones de la pregunta anterior.

```{r}
# código filtrando con score > tu_numero, y examinando los elementos
# de similitud más baja
```

**Pregunta**: considerando tus hallazgos, ¿cómo cambiarías el número
de hashes y bandas para mejorar tus resultados? ¿en qué sentido los mejoras?


**Pregunta** (si tienes tiempo) Evalúa tus resultados con las respuestas
correctas, que están en la carpeta de los datos.